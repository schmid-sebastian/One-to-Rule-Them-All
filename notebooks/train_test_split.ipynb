{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# Paths\n",
    "PROCESSED_DIR = \"../data/processed/\"\n",
    "TRAIN_DIR = \"../data/train/\"\n",
    "TEST_DIR = \"../data/test/\"\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "def generate_random_event_id(num_events):\n",
    "    \"\"\"Generates a list of unique random event IDs (short numeric format).\"\"\"\n",
    "    return random.sample(range(10_000_000, 99_999_999), num_events)  # 8-digit unique numbers\n",
    "\n",
    "def process_logs():\n",
    "    \"\"\"Processes event logs by replacing event_id with random IDs, then splitting into train/test sets.\"\"\"\n",
    "    log_files = glob.glob(os.path.join(PROCESSED_DIR, \"*.csv\"))  # Get all CSV files in processed folder\n",
    "\n",
    "    for log_file in log_files:\n",
    "        df = pd.read_csv(log_file)  # Load the log\n",
    "        \n",
    "        if \"event_id\" in df.columns:\n",
    "            df[\"event_id\"] = generate_random_event_id(len(df))  # Overwrite event_id with random UUIDs\n",
    "\n",
    "        # Get unique case IDs and shuffle\n",
    "        unique_cases = df[\"case_id\"].unique()\n",
    "        total_cases = len(unique_cases)\n",
    "        shuffled_cases = pd.Series(unique_cases).sample(frac=1, random_state=42).tolist()\n",
    "\n",
    "        # Split cases into train (80%) and test (20%)\n",
    "        split_idx = int(0.8 * total_cases)\n",
    "        train_cases = shuffled_cases[:split_idx]\n",
    "        test_cases = shuffled_cases[split_idx:]\n",
    "\n",
    "        # Create training and testing subsets\n",
    "        train_df = df[df[\"case_id\"].isin(train_cases)]\n",
    "        test_df = df[df[\"case_id\"].isin(test_cases)]\n",
    "\n",
    "        # Save to appropriate directories\n",
    "        base_filename = os.path.basename(log_file)  # Extract filename\n",
    "        train_file = os.path.join(TRAIN_DIR, base_filename)\n",
    "        test_file = os.path.join(TEST_DIR, base_filename)\n",
    "\n",
    "        train_df.to_csv(train_file, index=False)\n",
    "        test_df.to_csv(test_file, index=False)\n",
    "\n",
    "        print(f\"Processed {log_file}: Train -> {train_file}, Test -> {test_file}\")\n",
    "\n",
    "# Run the processing\n",
    "process_logs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
